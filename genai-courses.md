# Generative AI Courses

This page contains a list of courses related to Generative AI, Large Language Models (LLMs), and Natural Language Processing (NLP). The courses cover a range of topics from practical applications to theoretical foundations.


* [An Open Course on LLMs, Led by Practitioners](https://parlance-labs.com/education/): Hear from practitioners on a wide range of topics on LLMs, including RAG, evaluation, applications, fine-tuning and prompt engineering.

* [Introduction to LangGraph](https://academy.langchain.com/courses/intro-to-langgraph): Build reliable AI agents with LangChain Academy's Introduction to LangGraph course. You'll master graph-based workflows for agent construction. The course teaches memory integration and human-in-the-loop techniques for self-corrective agents. You'll create an AI assistant capable of performing knowledge tasks. Develop smarter, more adaptable AI systems using LangGraph's advanced features.

* [LLM University](https://cohere.com/llmu): Welcome to LLM University, your premier learning destination for mastering Enterprise AI technologies. Designed for developers and technical professionals, our hub offers comprehensive resources, expert-led courses, and step-by-step guides to help you start building quickly and stay ahead in the rapidly evolving AI landscape.

* [RAG++](https://www.wandb.courses/courses/rag-in-production): Practical RAG techniques for engineers: learn production-ready solutions from industry experts to optimize performance, cut costs, and enhance the accuracy and relevance of your applications.

* [Prompt Evaluations](https://github.com/anthropics/courses/tree/master/prompt_evaluations): Welcome to Anthropic's comprehensive prompt evaluations course. Across nine lessons, you will learn everything you need to know to implement evaluations successfully in your workflows with the Anthropic API. We recommend that you start from the beginning with the Evaluations 101 lesson, as each lesson builds on key concepts taught in previous ones.

* [Hugging Face Course](https://www.youtube.com/playlist?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o): this course teaches you all things about hungging face ecosystem. 

* [Large Language Model Course](https://github.com/mlabonne/llm-course): Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.

* [Large Language Models (llms) by Ibrahim Sobh](https://github.com/IbrahimSobh/llms): In this repository Language models are introduced covering both theoretical and practical aspects.

* [Large Language Models Course: Learn by Doing LLM Projects](https://github.com/peremartra/Large-Language-Model-Notebooks-Course): The course provides a hands-on experience using models from OpenAI and the Hugging Face library. We are going to see and use a lot of tools and practice with small projects that will grow as we can apply the new knowledge.

* [Foundation Models by Samuel Albanie](https://www.youtube.com/playlist?app=desktop&list=PL9t0xVFP90GD8hox0KipBkJcLX_C3ja67&si=tOsqTE5DTjXRHLLm#bottom-sheet): A playlist of videos describing foundation models: GPT-3, DINO, Flamingo, CLIP, Codex, BLOOMZ and Flan-PaLM.  The playlist also contains an introductory overview based on the Stanford report on Foundation Models.

* [Free Generative AI & Large Language Models Courses](https://learn.activeloop.ai/): In these free courses, you can learn how to train and fine tune LLMs for production, and how to use Langchain and vector databases in production.

* [The Transformer Layer by Layer: A conceptual, layer by layer explanation of the transformer model](https://mlbootcamp.ai/course.html?guid=d105240a-94e1-405b-be80-60056659c24c): The Transformer Layer By Layer" course explains the Transformer model, a key artifact in artificial intelligence, through a series of comprehensive yet understandable modules. 

* [TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2023-fall-65940): To make LLMs more accessible, it is crucial to improve their efficiency.This course will introduce efficient AI computing techniques that enable powerful deep learning applications on resource-constrained devices. Students will get hands-on experience deploying large language models (e.g., LLaMA 2) on a laptop.

* [Harvard CS197: AI Research Experiences](https://www.cs197.seas.harvard.edu/): This course will also teach you how to systematically read research papers, generate new ideas, and present them in slides or papers. You'll even learn valuable project management and team communication techniques used by top AI researchers. 

* [generative-ai-for-beginners by Microsoft](https://github.com/microsoft/generative-ai-for-beginners): Learn the fundamentals of building Generative AI applications with our 12-lesson comprehensive course by Microsoft Cloud Advocates. Each lesson covers a key aspect of Generative AI principles and application development. Throughout this course, we will be building our own Generative AI startup so you can get an understanding of what it takes to launch your ideas.

* [Large Language Models: Foundation Models from the Ground Up](https://www.youtube.com/playlist?list=PLTPXxbhUt-YWjMCDahwdVye8HW69p5NYS): This course dives into the details of LLM foundation models. You will learn the innovations that led to the proliferation of transformer-based architectures, from encoder models (BERT) to decoder models (GPT), to encoder-decoder models (T5). You will also learn about the recent breakthroughs that led to applications like ChatGPT.

* [hands-on-llms](https://github.com/iusztinpaul/hands-on-llms): Learn how to engineer your end-to-end LLM ecosystem: training, streaming, and inference pipelines | deploy & automate | work in progress...

* [LLMOps: Building Real-World Applications With Large Language Models](https://www.comet.com/site/llm-course/): Learn to build modern software with LLMs using the newest tools and techniques in the field. 

* [The Attention Mechanism in Large Language Models](https://www.youtube.com/playlist?list=PLs8w1Cdi-zva4fwKkl9EK13siFvL9Wewf): The first video is about self-attention and its intuition. The second video is about multi-head attention, and the math behind it.  The third video is about the entire architecture on transformer models. For all videos, only a basic understanding of high school math is needed. (The channel includes easy to grasp ML courses for begineers.)

* [LLM in Production Part I](https://www.youtube.com/playlist?list=PL3vkEKxWd-us5YvvuvYkjP_QGlgUq3tpA): A continuously updated podcast talks and lectures on "LLMs in Production" by MLOps Community has some 50+ talks on topics like Efficiently scaling and deploying Large Language Models, Obstacles faced while deploying LLMs, Ensuring accuracy and quality in LLM Driven products, and Large model training and inferencing with DeepSeepd library ([Part II](https://www.youtube.com/playlist?list=PL3vkEKxWd-uupBSWL-DbVJuCMqXO9Z3Z4))

* [Generative AI Foundations on AWS Technical Deep Dive Series](https://www.youtube.com/playlist?list=PLhr1KZpdzukf-xb0lmiU3G89GJXaDbAIF): Generative AI Foundations on AWS is a technical deep dive course that gives you the conceptual fundamentals, practical advice, and hands-on guidance to pre-train, fine-tune, and deploy state-of-the-art foundation models on AWS and beyond.

* [Generative AI learning path by Google](https://www.cloudskillsboost.google/journeys/118): This learning path guides you through a curated collection of content on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud.

* [Practical Large Language Models](https://www.youtube.com/playlist?list=PLB1nTQo4_y6ukBQYuQm0ZAmuj51hVMKrC): These are videos from a Practical LLM workshop organized by Aggregate Intellect. 

* [Development with Large Language Models Tutorial – OpenAI, Langchain, Agents, Chroma](https://www.youtube.com/watch?v=xZDB1naRUlk): FreeCodeCamp released another data science course focusing on LLM Engineering. This two hours course focuses on how to embed an LLM model on your own project using tools such as OpenAI, Langchain, Agents, Chroma, etc ([Colab Notebook](https://colab.research.google.com/drive/1gi2yDvvhUwLT7c8ZEXz6Yja3cG5P2owP?usp=sharing), [Source Code](https://github.com/pythonontheplane123/LLM_course_part_1)).

* [Getting Started with Generative AI](https://www.youtube.com/playlist?list=PLTzg8WR1gEHyngMtdoflAdQryg29-mPiL): In this video playlist, we will explore how we can use pre-trained models available in Hugging Face for Generative AI applications like Chat bot, Translation, Document Parsing, etc.

* [UMass CS685: Advanced Natural Language Processing (Spring 2023) by Mohit Iyyer](https://www.youtube.com/playlist?list=PLWnsVgP6CzaelCF_jmn5HrpOXzRAPNjWj): The course covers a lot of important topics critical to understanding generative ai and language models better N-Gram Models, Forward propagation in neural language models, Attention mechanisms and Transformer Language Models, Configuring transformer models and self attention models, Large Language Models, Parameter efficient adaptation and Instruction Tuning, Reinforecement Learning from Human Feedback (RHLF), Prompt engineering and augented LMs.

* [LangChain & Vector Databases in Production](https://learn.activeloop.ai/courses/langchain): Activeloop team has created a no-nonsense, applied course teaching how to build Application on Top of Large Language Models. 

* [Large Language Models: Application through Production by Databricks](https://www.youtube.com/playlist?list=PLTPXxbhUt-YWSR8wtILixhZLF9qB_1yZm): This course is aimed at developers, data scientists, and engineers looking to build LLM-centric applications with the latest and most popular frameworks. By the end of this course, you will have built an end-to-end LLM workflow that is ready for production!

* [LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/): The course delves into two main topics: (1) Retrieval Augmented Generation (RAG), a common LLM application that retrieves contextual documents from an external dataset, and (2) a guide to building a chatbot that responds to queries based on the content of your documents, rather than the information it has learned in training.

* [100% Offline ChatGPT Alternative? by Rob Mulla](https://www.youtube.com/watch?v=Coj72EzmX20): In this video, Rob showed how he was able to install an open source Large Language Model (LLM) called h2oGPT on his local computer for 100% private, 100% local chat with a GPT.

* [Prompt Engineering Course: How To Effectively Use ChatGPT & Other AI Language Models](https://www.youtube.com/playlist?list=PLYio3GBcDKsPP2_zuxEp8eCulgFjI5a3g): Learn the basics of prompt engineering, Gain an understanding of what makes a good & bad prompt, Find out how to create, evaluate, and refine your prompts, Learn about some advanced techniques that will help you make your outputs more random or funny, and much more!

* [LLM Avalanche by FunctionalTV](https://www.youtube.com/playlist?list=PLNESult6cnOmbG_Sh0Y6-PxWjDaxOuZVB): LLM Avalanche is a technical Large-Language Model (ChatGPT and the like) meetup held in San Francisco on Jun 26, 2023, preceding the Data+AI Summit.

* [Learn the fundamentals of generative AI for real-world applications by Andrew Ng](https://www.deeplearning.ai/courses/generative-ai-with-llms/): Gain foundational knowledge, practical skills, and a functional understanding of how generative AI works.

* [Hands-on training transformers by San Diego Machine Learning](https://www.youtube.com/playlist?list=PLmp4AHm0u1g0_dp3KViUFepC-xDsQIrS_): Get to understand the working of transformers which form the core of generative ai models. The training has 5 one hour long sessions on Understanding data preparation, Knowledge on pretraining models, Model finetuning for specific use-cases, and Inferencing and deployment strategies.

* [Learn about AI Language Models and Reinforcement Learning](https://www.youtube.com/playlist?list=PLbzjzOKeYPCpp3NCeQioevM0YpZa5VqcS): From GPT-3.5-turbo to RL algorithms, this playlist covers everything you need to know about these cutting-edge technologies. Whether you're a student, a researcher, or a tech enthusiast, this playlist will expand your knowledge and help you stay up-to-date with the latest trends in AI.

* [State of GPT by Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2): Learn about the training pipeline of GPT assistants like ChatGPT, from tokenization to pretraining, supervised finetuning, and Reinforcement Learning from Human Feedback (RLHF). Dive deeper into practical techniques and mental models for the effective use of these models, including prompting strategies, finetuning, the rapidly growing ecosystem of tools, and their future extensions.

* [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU&t=2040s): Starting with the foundational concepts, Jeremy introduces the architecture and mechanics that make these AI systems tick. He then delves into critical evaluations of GPT-4, illuminates practical uses of language models in code writing and data analysis, and offers hands-on tips for working with the OpenAI API. The video also provides expert guidance on technical topics such as fine-tuning, decoding tokens, and running private instances of GPT models.

* [LLM Bootcamp - Spring 2023 The Full Stack](https://www.youtube.com/playlist?list=PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ): The course teaches you launching your first LLM app, foundational knowledge for LLMs, performing knowledge retrieval, and deploying these models to production.

* [ChatGPT Prompt Engineering for Developers by Andrew Ng and Isa Fulford](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): Learn prompt engineering best practices for application development

* [ChatGPT Course – Use The OpenAI API to Code 5 Projects](https://www.youtube.com/watch?v=uRQH2CFvedY): Learn how to use the OpenAI API to create five projects, including a ChatGPT clone, a DALL-E Image Creator, and a SQL Generator. This is a dive deep into the world of the OpenAI API, exploring its diverse capabilities and potential applications.

* [HuggingFace Transformers Course](https://huggingface.co/course/chapter1/1): This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem — Transformers, Datasets, Tokenizers, and Accelerate — as well as the Hugging Face Hub. It’s completely free and without ads.

* [ChatGPT and Large Language Models (LLMs): A Practical Guide](https://zerotomastery.io/courses/large-language-models/): This course is designed to give you a deep understanding of how to use LLMs like ChatGPT, and how they work under-the-hood. That means you'll learn about concepts like Prompt Design and Fine-Tuning so that you understand how models are trained and even how to train your own model.

* [LangChain](https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5): LangChain is a framework for developing applications powered by language models. In short, it allows you to connect the OpenAI API to Google Drive, Gmail, or YouTube API.

* [LangChain v0.1.0 Launch](https://www.youtube.com/playlist?list=PLfaIDFEXuae0gBSJ9T0w7cu7iJZbH3T31): A series of videos highlighting key focus areas of LangChain 0.1

* [MIT Future of AI is Foundation Models & Self-Supervised Learning](https://www.futureofai.mit.edu/): In this non-technical series of lectures, we will start with the history of AI, then with what supervised learning and reinforcement learning is missing, and conclude with the deep practical and foundational implications of self-supervised learning and foundation models.

* [Stanford CS25 - Transformers United](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM): In this seminar, we examine the details of how transformers work, and dive deep into the different kinds of transformers and how they're applied in different fields.

* [COS 597G (Fall 2022): Understanding Large Language Models by Princeton University](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/): This course is intended to prepare you for performing cutting-edge research in natural language processing, especially topics related to pre-trained language models. This is an advanced graduate course and all the students are expected to have taken machine learning and NLP courses before and are familiar with deep learning models such as Transformers.

* [Rasa Algorithm Whiteboard - Transformers & Attention (Large Language Models)](https://www.youtube.com/watch?v=yGTUuEx3GkA&list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb&index=10): This Youtube course provides an explanation of the attention mechanisms.

* [CS324 lecture notes on Large Language Models (Winter 2022)](https://stanford-cs324.github.io/winter2022/lectures/): This is a course on understanding and developing large language models. Another related course is [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/) ([Github](https://github.com/stanford-cs324)). Note: No video lectures available for these two courses. 

* [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/):  In this course, students gain a thorough introduction to cutting-edge neural networks for NLP. I highly recommend the CS224N suggested reading list.

* [Stanford XCS224U: Natural Language Understanding](https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp): This professional Stanford Online course draws on theoretical concepts from linguistics, natural language processing, and machine learning. Topics include domain adaptation for supervised sentiment, retrieval augmented in-context learning, advanced behavioral evolution, analysis methods, and NLP methods ([Source code](https://github.com/cgpotts/cs224u)).

* [Arabic NLP resources](https://github.com/h9-tect/Arabic_NLP_resources/tree/main): Acollection of courses in NLP in Arabic.
