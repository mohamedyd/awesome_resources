# XAI Repos & Tools
 
* [ğ—«ğ—½ğ—¹ğ—¶ğ—¾ğ˜‚ğ—²](https://deel-ai.github.io/xplique/): Xplique is a Python library that aims to improve deep learning model explainability, by utilizing methods such as Grad-CAM and SHAP. Furthermore, the Xplique website includes numerous tutorials, so you can get started!

* [ PiML-Toolbox](https://github.com/SelfExplainML/PiML-Toolbox): PiML is a new Python toolbox for interpretable ML model development and validation. Through low-code interface and high-code APIs, PiML supports a growing list of inherently interpretable ML models.

* [XAI-Bench](https://github.com/abacusai/xai-bench): a library for benchmarking feature attribution techniques using synthetic data.

* [alibi](https://github.com/Explainable-ML/alibi): Alibi is an open source Python library aimed at ML model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.

* [Interpretable Machine Learning](https://github.com/Explainable-ML/interpretable-ml): A collection of code, notebooks, and resources for training interpretable machine learning (ML) models, explaining ML models, and debugging ML models for accuracy, discrimination, and security.

* [CARLA - Counterfactual And Recourse Library](https://github.com/carla-recourse/CARLA): CARLA is a python library to benchmark counterfactual explanation and recourse models. It comes out-of-the box with commonly used datasets and various machine learning models.